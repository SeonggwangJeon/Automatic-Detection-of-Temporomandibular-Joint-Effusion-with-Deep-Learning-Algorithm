{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1536cbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import cv2\n",
    "from collections import Counter as cnt\n",
    "from sklearn import metrics\n",
    "from torch import optim\n",
    "\n",
    "from collections import Counter as cnt\n",
    "from torchvision import transforms\n",
    "from keras import Sequential\n",
    "from torch import nn\n",
    "from torchvision import models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, accuracy_score, confusion_matrix\n",
    "\n",
    "from Mymodule.ModelHandler import *\n",
    "from Mymodule.Utils import *\n",
    "from Mymodule.GradCam import *\n",
    "from Mymodule.BatchHandler import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2575b570",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')\n",
    "model_name = 'vgg16'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ee0261",
   "metadata": {},
   "outputs": [],
   "source": [
    "def explort_imgs(images, parent_dir,candidates):\n",
    "    for i,image in enumerate(images):\n",
    "        file_path = os.path.join(parent_dir, f'{candidates[i]}')\n",
    "        print(file_path)\n",
    "        cv2.imwrite(file_path, image)\n",
    "    print('exported..done')\n",
    "    \n",
    "def calculate_zero_ratios(img):\n",
    "    w, h = img.shape\n",
    "    zeros = 0\n",
    "    for i in range(w):\n",
    "        for j in range(w):\n",
    "            if img[i, j] <= 0:\n",
    "                zeros += 1\n",
    "    return zeros / (w*h)\n",
    "\n",
    "class LayerActivation():\n",
    "    features = None    \n",
    "    def __init__(self, model, layer_num):\n",
    "        self.hook = model.base.features[layer_num].register_forward_hook(self.hook_fn)\n",
    "    def hook_fn(self, module, input, output):\n",
    "        self.features = output.cpu().data.numpy()\n",
    "    def remove(self):\n",
    "        self.hook.remove()\n",
    "\n",
    "        \n",
    "activation = {}\n",
    "\n",
    "def get_activation(name):\n",
    "    def hook(model, input, output):\n",
    "        activation[name] = output.detach()\n",
    "    return hook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1ef85d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "root = './Dataset/ForGradCam/'\n",
    "candidates = os.listdir(root)[1:]\n",
    "candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2748d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "images = []\n",
    "for i, candidate in enumerate(candidates):\n",
    "    if candidate[-3:] != 'png': continue\n",
    "        \n",
    "    image_path = os.path.join(root,candidate)\n",
    "    \n",
    "    if i <= 4 : \n",
    "        x_start = 200\n",
    "        y_start = 200\n",
    "        x_end = x_start + 300\n",
    "        y_end = y_start + 400\n",
    "    else : \n",
    "        x_start = 100\n",
    "        y_start = 200\n",
    "        x_end = x_start + 300\n",
    "        y_end = y_start + 400\n",
    "\n",
    "    \n",
    "    image = cv2.imread(image_path)[x_start:x_end, y_start:y_end]\n",
    "    print(candidate)\n",
    "    plt.imshow(image)\n",
    "    plt.show()\n",
    "    \n",
    "    image = cv2.resize(image,(140,140))\n",
    "    images.append(image)\n",
    "images = np.array(images).copy()\n",
    "test_y = np.zeros([7,1])\n",
    "print(images.shape)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43608382",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = GetLoader([], images, test_y, batch=len(test_y), test=True)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66d05a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_strategy in ['finetuning', 'fromscratch']:\n",
    "    for i,(data, label) in enumerate(test_loader):\n",
    "        data = data\n",
    "        label = label\n",
    "\n",
    "        MRI = candidates[i].split('_')[2]\n",
    "        model_save_path = f'./Model_for_effusion/vgg16_{MRI}_{train_strategy}.pt'\n",
    "        \n",
    "        model = get_model(model_name, device, pretrained=True)    \n",
    "        model.load_state_dict(torch.load(model_save_path))\n",
    "        model.eval()\n",
    "        \n",
    "        last_layer = model.base.features[-2]\n",
    "        cam = GradCAM(model=model, target_layer=last_layer, device=device)\n",
    "        grayscale_cam = cam(input_tensor=data, target_category=0)\n",
    "\n",
    "        \n",
    "    visuals = get_visuals(images/255, grayscale_cam)\n",
    "    explort_imgs(visuals, f'./Gradcamimages/{train_strategy}', candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f16a74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(model_name, device, pretrained=True)    \n",
    "model.load_state_dict(torch.load(model_save_path))\n",
    "\n",
    "conv_out = LayerActivation(model, 42)\n",
    "conv_out.remove()\n",
    "maps = conv_out.features\n",
    "\n",
    "fig = plt.figure(figsize=(13,4))\n",
    "fig.subplots_adjust(left=0, right=1, bottom=0, top=0.8, hspace=0.1, wspace=0.1)\n",
    "\n",
    "mean_zero_ratio = 0.0\n",
    "\n",
    "for i in range(512):\n",
    "    if i < 100:\n",
    "        ax = fig.add_subplot(5, 20, i+1, xticks=[], yticks=[])\n",
    "        ax.imshow(maps[0][i])\n",
    "    mean_zero_ratio += calculate_zero_ratios(maps[0][i])\n",
    "\n",
    "mean_zero_ratio /= 512\n",
    "print('%.4f' % mean_zero_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd40db41",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerActivation():\n",
    "    features = None    \n",
    "    def __init__(self, model, layer_num):\n",
    "        self.hook = model.base.features[layer_num].register_forward_hook(self.hook_fn)\n",
    "    def hook_fn(self, module, input, output):\n",
    "        self.features = output.cpu().data.numpy()\n",
    "    def remove(self):\n",
    "        self.hook.remove()\n",
    "\n",
    "        \n",
    "activation = {}\n",
    "\n",
    "def get_activation(name):\n",
    "    def hook(model, input, output):\n",
    "        activation[name] = output.detach()\n",
    "    return hook\n",
    "\n",
    "def calculate_zero_ratios(img):\n",
    "    w, h = img.shape\n",
    "    zeros = 0\n",
    "    for i in range(w):\n",
    "        for j in range(w):\n",
    "            if img[i, j] <= 0:\n",
    "                zeros += 1\n",
    "    return zeros / (w*h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674815fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = './Dataset/ForGradCam/'\n",
    "candidates = os.listdir(root)[1:]\n",
    "candidates\n",
    "\n",
    "x_start = 200\n",
    "y_start = 200\n",
    "x_end = x_start + 300\n",
    "y_end = y_start + 400\n",
    "\n",
    "MRIs = []\n",
    "images = []\n",
    "for i, candidate in enumerate(candidates):\n",
    "    if candidate[-3:] != 'png': continue\n",
    "    image_path = os.path.join(root,candidate)\n",
    "    MRIs.append(candidate.split('_')[2][:2])\n",
    "    \n",
    "    if i <= 4 : \n",
    "        x_start = 200\n",
    "        y_start = 200\n",
    "        x_end = x_start + 300\n",
    "        y_end = y_start + 400\n",
    "    else : \n",
    "        x_start = 100\n",
    "        y_start = 200\n",
    "        x_end = x_start + 300\n",
    "        y_end = y_start + 400\n",
    "        \n",
    "    image = cv2.imread(image_path)[x_start:x_end, y_start:y_end]\n",
    "    image = cv2.resize(image,(140,140))\n",
    "    images.append(image)\n",
    "images = np.array(images)\n",
    "test_y = np.zeros([7,1])\n",
    "print(images.shape)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4533e3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(7):\n",
    "    test_loader = GetLoader([], images[i][None], test_y[i][None], batch=len(test_y), test=True)  \n",
    "    for train_strategy in ['finetuning', 'fromscratch']:\n",
    "        device = torch.device('cuda:1')\n",
    "        model_name = 'vgg16'\n",
    "        model = get_model(model_name, device, pretrained=False)\n",
    "        MRI = MRIs[i]\n",
    "        model_path = f'./Model_for_effusion/vgg16_{MRI}_{train_strategy}.pt'\n",
    "        model.load_state_dict(torch.load(model_path))\n",
    "        conv_out = LayerActivation(model, 42)\n",
    "\n",
    "        for data, label in test_loader:\n",
    "            data, label = data.to(device), label.to(device)\n",
    "            labels = label.float()\n",
    "            logits = model(data)\n",
    "\n",
    "        conv_out.remove()\n",
    "\n",
    "        maps = conv_out.features\n",
    "\n",
    "        fig = plt.figure(figsize=(13,4))\n",
    "        fig.subplots_adjust(left=0, right=1, bottom=0, top=0.8, hspace=0.1, wspace=0.1)\n",
    "\n",
    "        mean_zero_ratio = 0.0\n",
    "\n",
    "        for j in range(512):\n",
    "            if j < 100:\n",
    "                ax = fig.add_subplot(5, 20, j+1, xticks=[], yticks=[])\n",
    "                ax.imshow(maps[0][j])\n",
    "            mean_zero_ratio += calculate_zero_ratios(maps[0][j])\n",
    "\n",
    "        mean_zero_ratio /= 512\n",
    "        plt.savefig(f'./Gradcamimages/{train_strategy}/{candidates[i][:-4]}_heatmap_{mean_zero_ratio}.png')\n",
    "        print('%.4f' % mean_zero_ratio)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JSG_image",
   "language": "python",
   "name": "jsg_image"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
